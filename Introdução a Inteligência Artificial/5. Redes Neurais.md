É um modelo baseado nas redes neurais naturais, ou seja, baseado nos neurônios.

# Exemplo Perceptron
Entre anos 40 e 50, desenvolveu-se o Modelo Perceptron, que é o processo de realizar conexões, similar ao processo de neuro plasticidade. 
![[Pasted image 20250428145550.png]]
Nesse modelo, envia-se um sinal na entrada, as conexões passam a ter pesos e esses sinais iram sair por uma porta a depender do peso da conexão.

**Exemplo:** Treino de implementação da porta logica AND.
Entrada: (1; 1)
Peso: (0; 0)
1. Aplica a função soma. Soma = x1(valor)w1(peso) + x2w2 = 1x0 + 1x0 = 0
2. Aplicar a função de Transferência. 
	**Regra da Linearidade:**
	y = 1, se s > $\theta$ (Linear de correção)
	y = 0, se s <= $\theta$ 
	
	**Soma <= 0,5 -> y = 0**; } Transferência 0 para saída da porta AND é um valor **errado**.
	**Soma > 0,5 -> y = 1**.
	
3. Ajuste do peso
	Calcular o erro: ***E = y^d(saída esperada) - y(saída atual)** = E = 1 - 0*
	Calcula o fator de Correção:
		***F = c(Porcentagem de correção de Erro) x E(Erro) x X(entrada da porta)***
		**c** é um valor percentual de correção, ele pode oscilar de 0 a 1, mas normalmente é usado a baixo de 0,5.
		*F1 = 0,5 x 1 x 1 = 0,5*
		l
		*F2 = 0,5 x 1 x1 = 0,5*
	Calcula novo peso:
		***W(novo) = W(saida) + F(fator de correção)***
		W1 = 0 + 0,5
		W1 = 0,5
		l
		W2 = 0 + 0,5
		W2 = 0,5

Entrada: (1; 1)
Peso: (0,5; 0,5)
1. Aplica a função soma. Soma = 1 x 0,5 + 1 x 0,5 = 1
2. Aplica a função Transferência. **Soma <= 0,5 -> y = 0, Soma > 0,5 -> y = 1** } Transferido 1 para a saída da porta AND. **Correto.**

A partir desse próximo caso, é utilizado o mesmo valor peso encontrado para calcular a soma e verificar a regra de linearidade
(1+0=0) Soma = 1 x 0,5 + 0 x 0,5 = 0,5 (y <= 0,5 = 0; y^d = 0)
(0+1=0) Soma = 0 x 0,5 + 0 x 0,5 = 0,5 (y <= 0,5 = 0; y^d = 0)
(0+0=0) Soma = 0 x 0,5 + 0 x 0,5 = 0 (y <= 0,5 = 0; y^d = 0)

# Arquitetura RNA
Adotam-se **Portas de limiar** para calcular se a saída está correta ou não
![[Pasted image 20250430145334.png]]
**O beneficio da Equação de Sigmoidal é por ser uma equação facil de derivar**
## Regras de aprendizado
### Regra de Hebb:
![[Pasted image 20250505141028.png]]
### Regra de Delta: 
![[Pasted image 20250505141106.png]]

## Modelo Perceptron
Os modelos de Redes Neurais possuem uma regra de treinamento, que tem como função ajustar as conexões a depender dos padrões.

**Aprendizagem Supervisionada**
	Conhece a saída desejada e é informado a rede para que ela compare com a saída processada. Se houver erro, a rede tenta corrigir até que as saídas sejam iguais.
**Aprendizagem não Supervisionada**
	A saída desejada é informada a partir da entrada processada, não é informado qual será a saída esperada.

Esses modelos de aprendizagem devem ser apresentado matematicamente.

Neste modelo, adota-se a função **Degrau Simétrico**

### Exemplo:
Treinar a rede para reconhecer branco e preto
- **Codificar as entradas:**
	![[Pasted image 20250430150316.png]]
- **Definir parametros:** Taxa de aprendizagem = 0,2, Delta ($\theta$) = 0, peso 0 = 0,4, peso 1 = -0,8, peso 2 = 0,3
	![[Pasted image 20250430150549.png]]

![[Pasted image 20250430153009.png]]
Para o padrão Saída esperada (d) = -1
**Passo 1:** Definir a saída da rede
	Soma = (-1)(0,4) + (-1)(-0,8) + (-1)(0,3) = 0,1
	y = +1, (uma vez que soma = 0,1 >= Delta = 0)
	Como d != y, resposta errada, tem que atualizar os pesos
**Passo 2:** Atualiza pesos
	W(novo) = W + X(taxa de aprendizagem) x Y(entrada da porta) x (Y^d - Y)(erro)
	w0 = 0.4 + 0,2(-1)(-1 – (+1)) = 0.8
	w1 = -0.8 + 0,2(-1)(-1 – (+1)) = -0.4
	w2 = 0.3 + 0,2(-1)(-1 – (+1)) = 0.7
**Passo 3:** Repete o passo 1 e verifica se a resposta está correta.

![[Pasted image 20250430153027.png]]
Usando os pesos atualizados, tenta agora verificar para as pretas
**Passo 1:** Definir a saída da rede
	Soma = (1)(0.8) + (1)(-0,4) + (1)(0.7) = 1.1
	y = +1 (uma vez que 1,1 >= 0)
	Como (d = y), não precisa atualizar pesos
	Resposta está correta


**Entrada:**
	![[Pasted image 20250430153238.png]]
**Saída desejada:**
	![[Pasted image 20250430153447.png]] = +1+1+1 = +1

**Passo 1:** Definir a saída da rede
	soma = (-1)(0.8) + (1)(-0,4) + (-1)(0.7) = -1.9
	y=-1 (Uma vez que -1,9 < 0)
	Como (d = y), não precisa atualizar pesos
	Resposta está correta

**Entrada:**
	![[Pasted image 20250430153556.png]]
**Saída desejada:**
	![[Pasted image 20250430153619.png]] = -1-1-1 = +1

**Passo 1:** Definir a saída da rede
	soma = (1)(0.8) + (-1)(-0,4) + (1)(0.7) = 1.9, y=1
	y=+1 (Uma vez que 1,9 >= 0)
	Como (d = y), não precisa atualizar pesos
	Resposta está correta

## Modelo Perceptron com múltiplas Camadas
### Algoritmo Backpropagation
![[Pasted image 20250507150354.png]]

Vai reduzindo gradativamente o erro, esse processo é chamado **Convergência**.

**Tipos de erros de Saída:**
- **Leans Means Square:**
	![[Pasted image 20250505142631.png]]
- **Root Means Square:**
	![[Pasted image 20250505142610.png]]

O Erro é dado por:
	![[Pasted image 20250505143109.png]]
	ej(n) -> Erro de um neurônio
	dj(n) -> Saída desejada
	yj(n) -> Saída atual

Soma dos erros:
	![[Pasted image 20250505143257.png]]

Valor de ativação associada aos neurônios
	![[Pasted image 20250505151131.png]]

Função de ativação:
	![[Pasted image 20250505144059.png]]

Para minimizar o erro, é feita uma derivação parcial
![[Pasted image 20250505144644.png]]
Cada valor está em função de outro valor. A soma dos erros está em função de um erro, o erro está em função da função de ativação, a função de ativação está em função do valor de ativação dos neurônios, e esse valor está em fução do peso **wji(n)**. Deste modo, o wji(n) é a variável final. Ou seja, wij(n) => x em y=f(x).

Assim, calcula-se o erro da seguinte forma
	![[Pasted image 20250505151756.png]]
	![[Pasted image 20250505151803.png]]
	Assim, temos:
	![[Pasted image 20250505151838.png]]

Com isso, chegamos a ![[Pasted image 20250505152402.png]] que é equivalente a [[#Regra de Delta]].

Assim, pode-se definir a [[#Regra de Delta]] como sendo:
![[Pasted image 20250507142219.png]]
Em que, 
- **Gradiente local:**
	![[Pasted image 20250507142421.png]]
- **Taxa de aprendizagem:** Normalmente é dado em até 20%

**De forma resumida:**
- Se o neuronio j é nó de saída, usa a equação de gradiente local:
	![[Pasted image 20250507142930.png]]
- Se o neurônio j é um nó de saída conectado a entrada de outro neurônio k:
	![[Pasted image 20250507142421.png]]

#### Dois passos da computação
**Passo para frente** (Primeiro Passo):
	Dado uma entrada, e um peso aleatório para o neuronio j e para o neuronio k, calcula-se a saída a partir da equação (erro):
	![[Pasted image 20250507143558.png]]
	em que, vj(n) é dado por:
	![[Pasted image 20250507143632.png]]
	Assim, calcula-se o erro final:
	![[Pasted image 20250505143109.png]]

**Passo de retropropagação:**
	É o processo recursivo de, a partir do erro calculado, calcular o **Gradiente Local**, Calcular o Gradiente de j e assim modificar o peso original para um novo peso.
	**Modificação dos pesos:**
	![[Pasted image 20250507144954.png]]
	em que o modificador dos pesos é dado por $\Delta$w = $\eta$$\delta$yj
	Contudo, alguns modelos requerem o calculo de uma constante de peso de momentum, dado por $\Delta$w(n) = $\eta$$\delta$(n)yj(n) + $\alpha$$\Delta$w(n-1), em suma, ele calcula o modificador de peso com base no que já foi calculado até agora.

#### Modos de treinamento Sequencial
Quando está sendo feito o treinamento, de uma LLM, ela adota o sistema de critério de parada quando o percentual de modificação dos pesos para cada geração for inferior a um dado percentual.
$E =  \frac{\Delta w(n) -  \Delta w(n-1)}{\Delta w(n-1)}$ 
